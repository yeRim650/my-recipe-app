# RAG 기반 레시피 추천 시스템 성능 평가 보고서

**날짜**: 2025-06-06

---

## 1. 벡터 검색 품질 평가 기준

다음 표는 벡터 검색 단계에서 후보(recipes)의 품질을 평가하기 위해 정의한 항목입니다.  
LLM 단계에서 최종적으로 3개의 레시피를 추출한다고 가정했을 때, 후보 풀에 얼마나 충분한 정답(relevant recipe)이 포함되어 있는지를 판단하기 위한 기준입니다.

| 항목              | 평가 포인트                                                                                                                                           |
|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|
| 연관어·문맥 포착  | 키워드에 직접 포함되지 않은 재료(예: 오징어, 전복 등)나 문맥적 표현(예: 바다 향, 시원한 맛 등)이 상위‐K 결과에 얼마나 반영되는지                                                                            |
| 요리 유형         | 요청한 조리법(예: 찜/무침/국 등)이 Top-K 결과 안에 충분히 포함되어 있는지                                                                                       |

---

## 2. 데이터 및 실험 설정

- **평가 쿼리 목록**: 총 15개의 쿼리 (Q1~Q15)  
  각 쿼리에는 사용자(또는 평가 작성자)가 입력한 자연어 쿼리(`query_text`)와, 해당 쿼리에 대해 “정답”으로 간주하는 레시피 ID 목록(`gt_ids`)이 주어져 있습니다.  

- **실험에 사용된 RAG 파이프라인**:  
  - 백엔드: `recipe_rag_pipeline.py` (Qdrant + SBERT(BM-K/KoSimCSE-bert) 기반)  
  - 추천 함수: `recommend_for_user(user_id, query, top_k)`  
  - 사용자 ID: `user_id = 1` (테스트용)  

- **실험 환경**:  
  - CPU 기반 PyTorch  
  - Qdrant 로컬 인스턴스 (포트 6333)  
  - SBERT 모델: `BM-K/KoSimCSE-bert` (mean pooling 방식)  

- **Top-K 후보 개수 설정**:  
  벡터 검색 단계에서 먼저 후보를 추출한 뒤, LLM(챗봇 등)에게 상위 3개를 선택하도록 가정합니다.  
  본 보고서에서는 **Top-15, Top-20, Top-30** 세 가지 후보 풀 크기로 실험을 진행하였습니다.  

---

## 3. 성능 평가 결과

각 쿼리(Q1~Q15)에 대해 Top-15, Top-20, Top-30일 때 다음 지표를 계산하였습니다.

- **Precision@K**: 상위 K개 후보 중 정답 레시피 개수 ÷ K  
- **Recall@K**: 상위 K개 후보 중 정답 레시피 개수 ÷ |Ground-Truth|  
- **Average Precision@K (AP@K)**: 순서까지 고려한 평균 정밀도 (0 ≤ AP@K ≤ 1)  

### 3.1 Aggregate Metrics (Top-15 / Top-20 / Top-30)

아래는 15개 쿼리에 대해 각각 Top-15, Top-20, Top-30일 때 계산된 Mean Precision, Mean Recall, 그리고 MAP(Mean Average Precision) 값입니다.

|   K   | Mean Precision@K | Mean Recall@K |    MAP@K    |
| :---: | :--------------: | :-----------: | :---------: |
|  15   |      0.151       |    0.435      |   0.200     |
|  20   |      0.140       |    0.537      |   0.241     |
|  30   |      0.107       |    0.615      |   0.230     |

- **Top-15**:  
  - Mean Precision@15 ≈ 0.151  
  - Mean Recall@15 ≈ 0.435  
  - MAP@15 ≈ 0.200  
  - → 후보 풀이 상대적으로 작아, 일부 쿼리에서 정답이 충분히 포함되지 않아 LLM 단계에서 3개의 정답을 골라내기 어려움

- **Top-20**:  
  - Mean Precision@20 ≈ 0.140  
  - Mean Recall@20 ≈ 0.537  
  - MAP@20 ≈ 0.241  
  - → Top-15 대비 Recall이 크게 상승하여, 절반 이상의 쿼리에서 3개 이상의 정답을 확보할 가능성 증가

- **Top-30**:  
  - Mean Precision@30 ≈ 0.107  
  - Mean Recall@30 ≈ 0.615  
  - MAP@30 ≈ 0.230  
  - → Recall은 더욱 올라가지만, 후보 풀이 커지며 Precision 하락 및 계산 비용 증가

#### └ Top-20에서 각 쿼리별 정답 포함 개수 (참조)

| query_id | query_text                         | \|gt\| | 포함된 정답 개수 (Top-20) |
|:--------:|:-----------------------------------|:------:|:---------------------------:|
| Q1       | 바다 내음 가득한 시원한 국물        |   8    |             4               |
| Q2       | 해물 풍미가 살아있는 얼큰한 찌개     |   5    |             3               |
| Q3       | 고소한 두부와 버섯이 어우러진 찌개    |   5    |             5               |
| Q4       | 고단백 닭가슴살 스테이크             |   5    |             2               |
| Q5       | 부드럽고 촉촉한 계란찜               |   5    |             3               |
| Q6       | 달콤한 과일을 곁들인 상큼한 샐러드    |   5    |             4               |
| Q7       | 깊은 국물 맛의 버섯탕                |   4    |             1               |
| Q8       | 신선한 야채가 듬뿍 들어간 비빔밥      |   6    |             3               |
| Q9       | 고소한 견과류 향이 느껴지는 스프      |   5    |             2               |
| Q10      | 시원한 매생이 순두부탕               |   5    |             3               |
| Q11      | 얼큰한 국물 찌개                     |   5    |             2               |
| Q12      | 바삭하게 튀긴 닭꼬치                |   5    |             3               |
| Q13      | 부드러운 찜 요리                     |   5    |             2               |
| Q14      | 달콤한 볶음밥                        |   5    |             3               |
| Q15      | 허브 향 구운 스테이크                |   5    |             2               |

\* |gt|는 해당 쿼리의 Ground-Truth 레시피 개수

---

## 4. Top-K 비교 및 결정 과정

1. **목표 설정**  
   - **최종 사용 시나리오**:  
     LLM(챗봇)에게 “3개의 레시피를 추천해 달라”고 요청한다.  
   - 따라서 벡터 검색 단계에서 추출한 후보 풀(Top-K) 안에 최소 3개의 정답 레시피가 포함되어야 함.  

2. **Recall 관점 검토**  
   - **Top-15**:  
     - Mean Recall@15 ≈ 0.435  
     - 몇몇 쿼리(Q7, Q10 등)에서 정답 포함 개수가 1~2개에 그쳐, LLM이 3개를 수집하기 어려울 수 있음  
   - **Top-20**:  
     - Mean Recall@20 ≈ 0.537  
     - Q1, Q2, Q3, Q5, Q6, Q8 등 다수 쿼리에서 3개 이상의 정답 제공  
     - 일부 어려운 쿼리(Q7, Q11, Q13, Q15 등)만 2개 이하로 포함  
   - **Top-30**:  
     - Mean Recall@30 ≈ 0.615  
     - Top-20 대비 더 많은 쿼리에서 3개 이상 정답 확보 (특히 Q4, Q7, Q11, Q13, Q15도 2→3개 이상으로 개선된 경우 존재)  
     - 단, 후보 풀이 많아져 Precision이 떨어지고 계산 비용이 상승  

3. **Precision‧Recall‧비용 종합 고려**  
   - **Top-15**:  
     - 후보 풀이 상대적으로 적어 전반적인 Recall이 부족  
     - LLM이 3개를 추천하기 어려워, 실제 시나리오에는 부적합  
   - **Top-20**:  
     - Mean Precision@20 ≈ 0.140, Mean Recall@20 ≈ 0.537  
     - Top-15보다 Recall이 충분히 개선되어, 다수 쿼리에서 3개 이상의 정답이 후보에 포함됨  
     - Precision도 합리적 수준 유지, 입력 토큰 수 및 계산 비용이 아직 과도하지 않음  
     - 일부 쿼리(Q7, Q11, Q13, Q15)에서 정답 3개 미달이나, 최종 LLM 단계에서 적절한 후처리(가중치 재평가 등)를 통해 보완 가능  
   - **Top-30**:  
     - Mean Precision@30 ≈ 0.107, Mean Recall@30 ≈ 0.615  
     - Recall은 더 올라가지만, 후보 풀이 너무 많아지면서 Precision 하락 및 연산량 증가  
     - LLM에게 넘길 토큰 수가 크게 늘어나 지연 시간이 발생할 가능성  

4. **결론**  
   - “LLM에게 최종 3개만 추천”한다는 가정 하에, 후보 풀 안에 최소 3개 이상의 정답이 포함될 확률을 적절히 확보하는 것이 핵심  
   - **Top-20**와 **Top-30**을 비교했을 때:  
     - Top-20: 계산 비용이 상대적으로 낮고, 절반 이상의 쿼리에서 이미 3개 이상의 정답을 확보  
     - Top-30: Recall은 더 올라가지만, Precision 하락과 후보 풀이 커짐에 따른 처리 비용 상승 부담  
   - 종합적으로, **Top-20**을 **추천(RAG) 파이프라인**의 후보 풀 크기로 결정  

---

**요약**:  
- Top-15보다 후보 풀이 작아 Recall이 부족했으며, Top-30은 Recall이 더 높지만 계산 비용과 불필요 후보가 늘어나 비효율적임.  
- Top-20은 Recall(≈0.537)·Precision(≈0.140)·MAP(≈0.241)의 균형이 가장 좋으며, 대부분의 쿼리에서 3개 이상의 정답을 확보하기에 적합하다.
